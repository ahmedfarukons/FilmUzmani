"""
Film Gurusu Chatbot - Streamlit Web ArayÃ¼zÃ¼
Akbank GenAI Bootcamp Projesi
"""
import os
import io
from contextlib import redirect_stdout, redirect_stderr
import streamlit as st
from dotenv import load_dotenv
from src.data_processor import DataProcessor
from src.rag_pipeline import RAGPipeline

# Sayfa yapÄ±landÄ±rmasÄ±
st.set_page_config(
    page_title="ğŸ¬ Film Uzmani",
    page_icon="ğŸ¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ile Ã¶zel stil
st.markdown("""
    <style>
    .main {
        background-color: #0e1117;
    }
    .stTextInput > div > div > input {
        background-color: #1e1e1e;
        color: #ffffff;
    }
    .chat-message {
        padding: 1.5rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        display: flex;
        flex-direction: column;
    }
    .user-message {
        background-color: #2b313e;
        border-left: 5px solid #4a9eff;
    }
    .bot-message {
        background-color: #1e2530;
        border-left: 5px solid #00d4aa;
    }
    .stButton > button {
        background-color: #00d4aa;
        color: white;
        font-weight: bold;
        border-radius: 5px;
        border: none;
        padding: 0.5rem 2rem;
    }
    .stButton > button:hover {
        background-color: #00b894;
    }
    h1 {
        color: #00d4aa;
        text-align: center;
        font-size: 3rem;
        margin-bottom: 0;
    }
    .subtitle {
        text-align: center;
        color: #888;
        font-size: 1.2rem;
        margin-bottom: 2rem;
    }
    </style>
    """, unsafe_allow_html=True)


def initialize_session_state():
    """Session state deÄŸiÅŸkenlerini baÅŸlatÄ±r"""
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    
    if 'rag_pipeline' not in st.session_state:
        st.session_state.rag_pipeline = None
    
    if 'vectorstore_loaded' not in st.session_state:
        st.session_state.vectorstore_loaded = False
    
    if 'system_ready' not in st.session_state:
        st.session_state.system_ready = False
    
    if 'selected_model' not in st.session_state:
        st.session_state.selected_model = "ollama"  # VarsayÄ±lan Ollama (lokal)


def auto_initialize_system():
    """Sistem aÃ§Ä±lÄ±ÅŸÄ±nda otomatik olarak RAG'i yÃ¼kle"""
    if os.path.exists("faiss_db") and not st.session_state.vectorstore_loaded:
        try:
            # SeÃ§ili modelle RAG baÅŸlat
            rag = RAGPipeline(model_provider=st.session_state.selected_model)
            rag.load_vectorstore()
            rag.create_qa_chain(k=2)  # Daha hÄ±zlÄ± iÃ§in 2
            st.session_state.rag_pipeline = rag
            st.session_state.vectorstore_loaded = True
            st.session_state.system_ready = True
            return True
        except Exception as e:
            # Fallback: Gemini baÅŸarÄ±sÄ±zsa Ollama ile deneyelim
            try:
                rag = RAGPipeline(model_provider="ollama")
                rag.load_vectorstore()
                rag.create_qa_chain(k=2)
                st.session_state.rag_pipeline = rag
                st.session_state.vectorstore_loaded = True
                st.session_state.system_ready = True
                st.session_state.selected_model = "ollama"
                return True
            except Exception:
                st.session_state.system_ready = False
                return False
    elif not os.path.exists("faiss_db"):
        st.session_state.system_ready = False
        return False
    return st.session_state.vectorstore_loaded


def process_data():
    """Veri iÅŸleme ve vektÃ¶r veritabanÄ± oluÅŸturma"""
    try:
        with st.spinner("ğŸ“Š Veriler iÅŸleniyor..."):
            # Data processor oluÅŸtur
            processor = DataProcessor(chunk_size=1000, chunk_overlap=200)
            
            # Veri dizinini kontrol et
            if not os.path.exists('data'):
                st.error("âŒ 'data' klasÃ¶rÃ¼ bulunamadÄ±!")
                return False
            
            # Verileri iÅŸle
            # Streamlit stdout/stderr kapalÄ± olabilir; gÃ¼venli yÃ¶nlendirme kullan
            with redirect_stdout(io.StringIO()), redirect_stderr(io.StringIO()):
                documents = processor.process_directory('data')
            
            if len(documents) == 0:
                st.error("âŒ Ä°ÅŸlenecek veri bulunamadÄ±!")
                return False
            
            st.info(f"ğŸ“„ {len(documents)} chunk oluÅŸturuldu")
            
        with st.spinner("ğŸ”¨ VektÃ¶r veritabanÄ± oluÅŸturuluyor..."):
            # RAG pipeline oluÅŸtur (seÃ§ili model ile)
            with redirect_stdout(io.StringIO()), redirect_stderr(io.StringIO()):
                rag = RAGPipeline(model_provider=st.session_state.selected_model)
            
            # VektÃ¶r veritabanÄ± oluÅŸtur
            # OlasÄ± print'leri gÃ¼venli ÅŸekilde yÃ¶nlendir
            with redirect_stdout(io.StringIO()), redirect_stderr(io.StringIO()):
                rag.create_vectorstore(documents)
            
            # QA zinciri oluÅŸtur (k=2 daha hÄ±zlÄ±)
            with redirect_stdout(io.StringIO()), redirect_stderr(io.StringIO()):
                rag.create_qa_chain(k=2)
            
            st.session_state.rag_pipeline = rag
            st.session_state.vectorstore_loaded = True
            st.session_state.system_ready = True
            
            st.success(f"âœ… VektÃ¶r veritabanÄ± baÅŸarÄ±yla oluÅŸturuldu! ({len(documents)} chunk)")
            return True
            
    except Exception as e:
        st.error(f"âŒ Veri iÅŸleme hatasÄ±: {str(e)}")
        return False


def display_chat_message(role: str, content: str):
    """Chat mesajÄ±nÄ± gÃ¶sterir"""
    if role == "user":
        st.markdown(f"""
        <div class="chat-message user-message">
            <strong>ğŸ‘¤ Sen:</strong><br>
            {content}
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div class="chat-message bot-message">
            <strong>ğŸ¬ Film Gurusu:</strong><br>
            {content}
        </div>
        """, unsafe_allow_html=True)


def main():
    """Ana uygulama fonksiyonu"""
    # Session state baÅŸlat
    initialize_session_state()
    
    # Otomatik sistem baÅŸlatma
    auto_initialize_system()
    
    # BaÅŸlÄ±k
    st.markdown("<h1>ğŸ¬ Film Gurusu</h1>", unsafe_allow_html=True)
    st.markdown("<p class='subtitle'>RAG TabanlÄ± Film EleÅŸtiri Chatbot'u - Tamamen Lokal</p>", unsafe_allow_html=True)
    
    # Sidebar - Kontrol Paneli
    with st.sidebar:
        st.header("ğŸ¤– Model SeÃ§imi")
        
        # Model seÃ§ici
        new_model = st.radio(
            "LLM Modeli:",
            options=["gemini", "ollama"],
            format_func=lambda x: "ğŸš€ Gemini 1.5 Flash (HÄ±zlÄ±)" if x == "gemini" else "ğŸ  Ollama Phi-3 (Lokal)",
            index=0 if st.session_state.selected_model == "gemini" else 1,
            help="Gemini: HÄ±zlÄ± ve gÃ¼Ã§lÃ¼ (API key gerekli)\nOllama: Tamamen lokal (yavaÅŸ olabilir)"
        )
        
        # Model deÄŸiÅŸtiyse sistemi resetle
        if new_model != st.session_state.selected_model:
            st.session_state.selected_model = new_model
            st.session_state.vectorstore_loaded = False
            st.session_state.system_ready = False
            st.session_state.rag_pipeline = None
            st.info("ğŸ”„ Model deÄŸiÅŸti, sistem yeniden baÅŸlatÄ±lÄ±yor...")
            st.rerun()
        
        # API key kontrolÃ¼ (sadece Gemini iÃ§in)
        if st.session_state.selected_model == "gemini":
            load_dotenv()
            gemini_key = os.getenv('GEMINI_API_KEY')
            if not gemini_key:
                st.error("âš ï¸ GEMINI_API_KEY bulunamadÄ±!")
                st.info("ğŸ“ .env dosyasÄ±na ekleyin:\n```\nGEMINI_API_KEY=your_key_here\n```")
            else:
                st.success("âœ… API Key: " + gemini_key[:8] + "...")
        
        st.divider()
        
        st.header("ğŸ“Š Sistem Durumu")
        
        # Sistem durumu gÃ¶stergesi
        if st.session_state.system_ready and st.session_state.vectorstore_loaded:
            st.success("ğŸŸ¢ **Sistem HazÄ±r**")
            model_name = "Gemini 1.5 Flash" if st.session_state.selected_model == "gemini" else "Ollama Phi-3 Mini"
            st.info(f"ğŸ¤– **Model:** {model_name}\nğŸ’¾ **VektÃ¶r DB:** FAISS (Aktif)")
        elif os.path.exists("faiss_db") and not st.session_state.vectorstore_loaded:
            st.warning("ğŸŸ¡ **YÃ¼kleniyor...**")
            if st.button("ğŸ”„ Yeniden YÃ¼kle"):
                st.session_state.vectorstore_loaded = False
                st.rerun()
        else:
            st.error("ğŸ”´ **VeritabanÄ± Yok**")
            st.info("ğŸ’¡ Ã–nce verileri iÅŸleyin")
        
        st.divider()
        
        # Veri Ä°ÅŸleme
        st.header("ğŸ“š Veri YÃ¶netimi")
        if st.button("ğŸ”„ Verileri Ä°ÅŸle / GÃ¼ncelle"):
            if process_data():
                st.rerun()
        
        st.caption("ğŸ’¡ Yeni veri eklediyseniz bu butona tÄ±klayÄ±n")
        
        st.divider()
        
        # Sohbet KontrolÃ¼
        st.header("ğŸ’¬ Sohbet")
        if st.button("ğŸ—‘ï¸ Sohbeti Temizle"):
            st.session_state.messages = []
            st.rerun()
        
        st.metric("Mesaj SayÄ±sÄ±", len(st.session_state.messages))
        
        st.divider()
        
        # HakkÄ±nda
        st.header("â„¹ï¸ HakkÄ±nda")
        st.markdown("""
        **Film Gurusu Chatbot**
        
        RAG teknolojisiyle film eleÅŸtirileri 
        Ã¼zerine sorularÄ±nÄ±zÄ± yanÄ±tlar.
        
        **Teknolojiler:**
        - ğŸ¤– Gemini / Ollama
        - ğŸ”— LangChain
        - ğŸ’¾ FAISS VektÃ¶r DB
        - ğŸ¨ Streamlit
        - ğŸ§  Transformers Embeddings
        
        **Hybrid Model DesteÄŸi!**
        
        ---
        *Akbank GenAI Bootcamp*
        """)
    
    # Ana iÃ§erik - Chat arayÃ¼zÃ¼
    if not st.session_state.vectorstore_loaded:
        st.warning("âš ï¸ VektÃ¶r veritabanÄ± bulunamadÄ±!")
        st.info("ğŸ’¡ Sol panelden 'ğŸ”„ Verileri Ä°ÅŸle / GÃ¼ncelle' butonuna tÄ±klayÄ±n.")
        
        # Ã–rnek sorular gÃ¶ster
        st.subheader("ğŸ’¡ HazÄ±r Olunca Sorabilecekleriniz:")
        example_questions = [
            "Christopher Nolan'Ä±n hangi filmleri hakkÄ±nda eleÅŸtiri var?",
            "En iyi puan alan filmler hangileri?",
            "Duygusal filmler Ã¶nerir misin?",
            "Hangi filmler sosyal eleÅŸtiri iÃ§eriyor?",
            "Aksiyon filmleri Ã¶ner"
        ]
        
        for question in example_questions:
            st.markdown(f"- {question}")
    
    else:
        # Chat geÃ§miÅŸini gÃ¶ster
        for message in st.session_state.messages:
            display_chat_message(message["role"], message["content"])
        
        # KullanÄ±cÄ± giriÅŸi
        user_question = st.chat_input("Film hakkÄ±nda bir ÅŸey sor... ğŸ¬")
        
        if user_question:
            # KullanÄ±cÄ± mesajÄ±nÄ± ekle
            st.session_state.messages.append({
                "role": "user",
                "content": user_question
            })
            
            # KullanÄ±cÄ± mesajÄ±nÄ± gÃ¶ster
            display_chat_message("user", user_question)
            
            # Bot cevabÄ±nÄ± al
            with st.spinner("ğŸ¤” DÃ¼ÅŸÃ¼nÃ¼yorum..."):
                try:
                    result = st.session_state.rag_pipeline.query(user_question)
                    bot_response = result['answer']
                    
                    # Bot mesajÄ±nÄ± ekle
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": bot_response
                    })
                    
                    # Bot mesajÄ±nÄ± gÃ¶ster
                    display_chat_message("assistant", bot_response)
                    
                    # Kaynak belgeleri gÃ¶ster (expander iÃ§inde)
                    if result['source_documents']:
                        with st.expander("ğŸ“š Kaynak Belgeler"):
                            for i, doc in enumerate(result['source_documents'], 1):
                                st.markdown(f"**Kaynak {i}:**")
                                st.text(doc.page_content[:300] + "...")
                                st.divider()
                    
                except Exception as e:
                    error_message = f"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {str(e)}"
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": error_message
                    })
                    display_chat_message("assistant", error_message)
            
            # SayfayÄ± yenile
            st.rerun()


if __name__ == "__main__":
    # UygulamayÄ± Ã§alÄ±ÅŸtÄ±r
    main()

