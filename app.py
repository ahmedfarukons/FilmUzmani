"""
Film Gurusu Chatbot - Streamlit Web ArayÃ¼zÃ¼
Akbank GenAI Bootcamp Projesi
"""
import os
import streamlit as st
from dotenv import load_dotenv
from src.data_processor import DataProcessor
from src.rag_pipeline import RAGPipeline

# Sayfa yapÄ±landÄ±rmasÄ±
st.set_page_config(
    page_title="ğŸ¬ Film Uzmani",
    page_icon="ğŸ¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ile Ã¶zel stil
st.markdown("""
    <style>
    .main {
        background-color: #0e1117;
    }
    .stTextInput > div > div > input {
        background-color: #1e1e1e;
        color: #ffffff;
    }
    .chat-message {
        padding: 1.5rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        display: flex;
        flex-direction: column;
    }
    .user-message {
        background-color: #2b313e;
        border-left: 5px solid #4a9eff;
    }
    .bot-message {
        background-color: #1e2530;
        border-left: 5px solid #00d4aa;
    }
    .stButton > button {
        background-color: #00d4aa;
        color: white;
        font-weight: bold;
        border-radius: 5px;
        border: none;
        padding: 0.5rem 2rem;
    }
    .stButton > button:hover {
        background-color: #00b894;
    }
    h1 {
        color: #00d4aa;
        text-align: center;
        font-size: 3rem;
        margin-bottom: 0;
    }
    .subtitle {
        text-align: center;
        color: #888;
        font-size: 1.2rem;
        margin-bottom: 2rem;
    }
    </style>
    """, unsafe_allow_html=True)


def initialize_session_state():
    """Session state deÄŸiÅŸkenlerini baÅŸlatÄ±r"""
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    
    if 'rag_pipeline' not in st.session_state:
        st.session_state.rag_pipeline = None
    
    if 'vectorstore_loaded' not in st.session_state:
        st.session_state.vectorstore_loaded = False
    
    if 'api_key_configured' not in st.session_state:
        st.session_state.api_key_configured = False
    
    if 'model_provider' not in st.session_state:
        st.session_state.model_provider = "ollama"


def load_rag_pipeline(model_provider: str, groq_api_key: str = None):
    """RAG Pipeline'Ä± yÃ¼kler"""
    try:
        with st.spinner("ğŸ”„ RAG sistemi yÃ¼kleniyor..."):
            # Model provider'a gÃ¶re pipeline oluÅŸtur
            rag = RAGPipeline(
                model_provider=model_provider,
                groq_api_key=groq_api_key
            )
            
            # VeritabanÄ± kontrolÃ¼
            if os.path.exists("chroma_db"):
                rag.load_vectorstore()
                rag.create_qa_chain(k=4)
                st.session_state.vectorstore_loaded = True
                st.session_state.rag_pipeline = rag
                st.session_state.model_provider = model_provider
                st.success(f"âœ… RAG sistemi baÅŸarÄ±yla yÃ¼klendi! ({model_provider.upper()})")
                return True
            else:
                st.warning("âš ï¸ VektÃ¶r veritabanÄ± bulunamadÄ±. LÃ¼tfen Ã¶nce verileri iÅŸleyin.")
                return False
                
    except Exception as e:
        st.error(f"âŒ RAG sistemi yÃ¼klenirken hata: {str(e)}")
        return False


def process_data(model_provider: str, groq_api_key: str = None):
    """Veri iÅŸleme ve vektÃ¶r veritabanÄ± oluÅŸturma"""
    try:
        with st.spinner("ğŸ“Š Veriler iÅŸleniyor..."):
            # Data processor oluÅŸtur
            processor = DataProcessor(chunk_size=1000, chunk_overlap=200)
            
            # Veri dizinini kontrol et
            if not os.path.exists('data'):
                st.error("âŒ 'data' klasÃ¶rÃ¼ bulunamadÄ±!")
                return False
            
            # Verileri iÅŸle
            documents = processor.process_directory('data')
            
            if len(documents) == 0:
                st.error("âŒ Ä°ÅŸlenecek veri bulunamadÄ±!")
                return False
            
            st.info(f"ğŸ“„ {len(documents)} chunk oluÅŸturuldu")
            
        with st.spinner("ğŸ”¨ VektÃ¶r veritabanÄ± oluÅŸturuluyor..."):
            # RAG pipeline oluÅŸtur
            rag = RAGPipeline(
                model_provider=model_provider,
                groq_api_key=groq_api_key
            )
            
            # VektÃ¶r veritabanÄ± oluÅŸtur
            rag.create_vectorstore(documents)
            
            # QA zinciri oluÅŸtur
            rag.create_qa_chain(k=4)
            
            st.session_state.rag_pipeline = rag
            st.session_state.vectorstore_loaded = True
            
            st.success(f"âœ… VektÃ¶r veritabanÄ± baÅŸarÄ±yla oluÅŸturuldu! ({len(documents)} chunk)")
            return True
            
    except Exception as e:
        st.error(f"âŒ Veri iÅŸleme hatasÄ±: {str(e)}")
        return False


def display_chat_message(role: str, content: str):
    """Chat mesajÄ±nÄ± gÃ¶sterir"""
    if role == "user":
        st.markdown(f"""
        <div class="chat-message user-message">
            <strong>ğŸ‘¤ Sen:</strong><br>
            {content}
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div class="chat-message bot-message">
            <strong>ğŸ¬ Film Gurusu:</strong><br>
            {content}
        </div>
        """, unsafe_allow_html=True)


def main():
    """Ana uygulama fonksiyonu"""
    # Session state baÅŸlat
    initialize_session_state()
    
    # BaÅŸlÄ±k
    st.markdown("<h1>ğŸ¬ Film Gurusu</h1>", unsafe_allow_html=True)
    st.markdown("<p class='subtitle'>RAG TabanlÄ± Film EleÅŸtiri Chatbot'u</p>", unsafe_allow_html=True)
    
    # Sidebar - Ayarlar
    with st.sidebar:
        st.header("âš™ï¸ Ayarlar")
        
        # API Key'leri .env'den otomatik yÃ¼kle
        load_dotenv()
        groq_api_key = os.getenv('GROQ_API_KEY')
        
        # Model SeÃ§imi
        st.subheader("ğŸ¤– Model SeÃ§imi")
        model_provider = st.selectbox(
            "LLM Provider",
            ["ollama", "groq"],
            index=0,  # Ollama varsayÄ±lan (lokal)
            help="Hangi AI modelini kullanmak istiyorsunuz?"
        )
        
        # Model bilgileri ve API key durumu
        if model_provider == "ollama":
            st.info("ğŸ  **Ollama - Phi-3 Mini (3.8B)**\n- Tamamen LOKAL\n- API key gerektirmez\n- Offline Ã§alÄ±ÅŸÄ±r\n- CPU'da hÄ±zlÄ±")
            st.success("âœ… Ollama: Lokal (API key gerekmez)")
            keys_configured = True  # Ollama iÃ§in API key gerekmez
            
        elif model_provider == "groq":
            st.info("âš¡ **Groq - Llama 3.2 90B**\n- Ã‡ok hÄ±zlÄ±\n- Ãœcretsiz kuota\n- TÃ¼rkÃ§e desteÄŸi mÃ¼kemmel")
            if groq_api_key:
                st.success("âœ… Groq API: Aktif")
                keys_configured = True
            else:
                st.warning("âš ï¸ Groq API key bulunamadÄ± (.env dosyasÄ±na GROQ_API_KEY ekleyin)")
                st.info("ğŸ”— API key almak iÃ§in: https://console.groq.com/keys")
                keys_configured = False
        
        st.session_state.api_key_configured = keys_configured
        
        st.divider()
        
        # RAG sistemi yÃ¼kleme
        st.header("ğŸš€ Sistem KontrolÃ¼")
        
        if keys_configured:
            # RAG sistemi yÃ¼kleme butonu
            if not st.session_state.vectorstore_loaded:
                if st.button("ğŸš€ RAG Sistemini BaÅŸlat"):
                    success = load_rag_pipeline(model_provider, groq_api_key)
                    if not success:
                        st.info("ğŸ’¡ VektÃ¶r veritabanÄ± yoksa, Ã¶nce 'Verileri Ä°ÅŸle' butonuna tÄ±klayÄ±n")
            else:
                current_model = st.session_state.model_provider.upper()
                st.success(f"âœ… RAG sistemi aktif ({current_model})")
                
                # Model deÄŸiÅŸikliÄŸi kontrolÃ¼
                if st.session_state.model_provider != model_provider:
                    st.warning(f"âš ï¸ Model deÄŸiÅŸti! Yeniden baÅŸlatÄ±n.")
                    if st.button("ğŸ”„ Modeli DeÄŸiÅŸtir"):
                        st.session_state.vectorstore_loaded = False
                        st.rerun()
        else:
            st.warning("âš ï¸ Groq kullanmak iÃ§in API key gerekli")
        
        st.divider()
        
        # Veri iÅŸleme bÃ¶lÃ¼mÃ¼
        st.header("ğŸ“š Veri YÃ¶netimi")
        
        if keys_configured:
            if st.button("ğŸ”„ Verileri Ä°ÅŸle"):
                if process_data(model_provider, groq_api_key):
                    st.rerun()
            
            st.caption("ğŸ’¡ Yeni veri eklediyseniz, bu butona tÄ±klayarak veritabanÄ±nÄ± gÃ¼ncelleyin.")
        else:
            st.warning("âš ï¸ Groq kullanmak iÃ§in API key gerekli")
        
        st.divider()
        
        # Sohbet temizleme
        st.header("ğŸ’¬ Sohbet")
        if st.button("ğŸ—‘ï¸ Sohbeti Temizle"):
            st.session_state.messages = []
            st.rerun()
        
        st.divider()
        
        # Ä°statistikler
        st.header("ğŸ“Š Ä°statistikler")
        st.metric("Mesaj SayÄ±sÄ±", len(st.session_state.messages))
        
        if st.session_state.vectorstore_loaded:
            st.success("ğŸŸ¢ VeritabanÄ±: Aktif")
        else:
            st.error("ğŸ”´ VeritabanÄ±: Pasif")
        
        st.divider()
        
        # HakkÄ±nda
        st.header("â„¹ï¸ HakkÄ±nda")
        st.markdown("""
        **Film Gurusu Chatbot**
        
        Bu chatbot, RAG (Retrieval-Augmented Generation) 
        teknolojisi kullanarak film eleÅŸtirileri Ã¼zerine 
        sorularÄ±nÄ±zÄ± yanÄ±tlar.
        
        **Teknolojiler:**
        - ğŸ¤– Ollama (Phi-3 Mini) / Groq (Llama 3.2 90B)
        - ğŸ”— LangChain
        - ğŸ’¾ ChromaDB (VektÃ¶r DB)
        - ğŸ¨ Streamlit
        - ğŸ§  Custom Transformers (Lokal Embedding)
        
        ---
        *Akbank GenAI Bootcamp*  
        *Yeni Nesil Proje KampÄ±*
        """)
    
    # Ana iÃ§erik - Chat arayÃ¼zÃ¼
    if not st.session_state.api_key_configured:
        st.warning("âš ï¸ API Key gerekli!")
        st.info("ğŸ“ Groq kullanmak iÃ§in `.env` dosyasÄ±na API key ekleyin:")
        st.code("""
# .env dosyasÄ±
GROQ_API_KEY=your_groq_api_key_here
        """, language="bash")
        st.info("ğŸ”— Ãœcretsiz Groq API key almak iÃ§in: https://console.groq.com/keys")
        st.divider()
        st.success("ğŸ’¡ **Veya Ollama kullanÄ±n** (API key gerekmez, tamamen lokal!)")
        st.info("Sol panelden 'ollama' seÃ§eneÄŸini seÃ§in ve direkt baÅŸlayÄ±n.")
        
        # Ã–rnek sorular
        st.subheader("ğŸ’¡ HazÄ±r Olunca Sorabilecekleriniz:")
        example_questions = [
            "Christopher Nolan'Ä±n hangi filmleri hakkÄ±nda eleÅŸtiri var?",
            "En iyi puan alan filmler hangileri?",
            "Parasite filmi hakkÄ±nda ne sÃ¶yleniyor?",
            "Duygusal filmler Ã¶nerir misin?",
            "Hangi filmler sosyal eleÅŸtiri iÃ§eriyor?"
        ]
        
        for question in example_questions:
            st.markdown(f"- {question}")
    
    elif not st.session_state.vectorstore_loaded:
        st.warning("âš ï¸ RAG sistemi henÃ¼z yÃ¼klenmedi. LÃ¼tfen sol panelden 'ğŸš€ RAG Sistemini BaÅŸlat' butonuna tÄ±klayÄ±n.")
        st.info("ğŸ’¡ EÄŸer vektÃ¶r veritabanÄ± yoksa, Ã¶nce 'ğŸ”„ Verileri Ä°ÅŸle' butonuna tÄ±klayÄ±n.")
    
    else:
        # Chat geÃ§miÅŸini gÃ¶ster
        for message in st.session_state.messages:
            display_chat_message(message["role"], message["content"])
        
        # KullanÄ±cÄ± giriÅŸi
        user_question = st.chat_input("Film hakkÄ±nda bir ÅŸey sor... ğŸ¬")
        
        if user_question:
            # KullanÄ±cÄ± mesajÄ±nÄ± ekle
            st.session_state.messages.append({
                "role": "user",
                "content": user_question
            })
            
            # KullanÄ±cÄ± mesajÄ±nÄ± gÃ¶ster
            display_chat_message("user", user_question)
            
            # Bot cevabÄ±nÄ± al
            with st.spinner("ğŸ¤” DÃ¼ÅŸÃ¼nÃ¼yorum..."):
                try:
                    result = st.session_state.rag_pipeline.query(user_question)
                    bot_response = result['answer']
                    
                    # Bot mesajÄ±nÄ± ekle
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": bot_response
                    })
                    
                    # Bot mesajÄ±nÄ± gÃ¶ster
                    display_chat_message("assistant", bot_response)
                    
                    # Kaynak belgeleri gÃ¶ster (expander iÃ§inde)
                    if result['source_documents']:
                        with st.expander("ğŸ“š Kaynak Belgeler"):
                            for i, doc in enumerate(result['source_documents'], 1):
                                st.markdown(f"**Kaynak {i}:**")
                                st.text(doc.page_content[:300] + "...")
                                st.divider()
                    
                except Exception as e:
                    error_message = f"ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {str(e)}"
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": error_message
                    })
                    display_chat_message("assistant", error_message)
            
            # SayfayÄ± yenile
            st.rerun()


if __name__ == "__main__":
    # .env dosyasÄ±nÄ± yÃ¼kle
    load_dotenv()
    
    # UygulamayÄ± Ã§alÄ±ÅŸtÄ±r
    main()

